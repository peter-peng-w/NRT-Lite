{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from utils.data_reader import amazon_dataset_iters\n",
    "import torch.utils.tensorboard as tb\n",
    "from os import path\n",
    "from models.nrt import NRT\n",
    "import utils.constants as constants\n",
    "from utils.loss import mask_nll_loss, review_loss\n",
    "import math\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peng/MyProgram/venv_MLDL/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/peng/MyProgram/venv_MLDL/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peng/MyProgram/venv_MLDL/lib/python3.8/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets loaded\n",
      "item vocab built\n",
      "user vocab built\n",
      "text vocab built\n",
      "tips vocab built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peng/MyProgram/venv_MLDL/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Loading the dataset\n",
    "dataset_folder = './data/Musical_Instruments_5/'\n",
    "text_vocab, tips_vocab, train_iter, val_iter, test_iter = (\n",
    "    amazon_dataset_iters(dataset_folder)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peng/MyProgram/venv_MLDL/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Count user and item number\n",
    "items_count = int(max([i.item.max().cpu().data.numpy() for i in train_iter] + [i.item.max().cpu().data.numpy() for i in test_iter]))\n",
    "users_count = int(max([i.user.max().cpu().data.numpy() for i in train_iter] + [i.user.max().cpu().data.numpy() for i in test_iter]))\n",
    "vocab_size = len(text_vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = NRT(\n",
    "        users_count + 2,\n",
    "        items_count + 2,\n",
    "        constants.EBD_SIZE,\n",
    "        constants.RATER_MLP_SIZES,\n",
    "        constants.HIDDEN_DIM,\n",
    "        vocab_size,\n",
    "        constants.WORD_LF_NUM,\n",
    "        constants.TG_HIDDEN_LAYERS,\n",
    "        constants.DROPOUT_RATE,\n",
    "        constants.RNN_TYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "alpha = constants.RR_LOSS_WEIGHT\n",
    "beta = constants.WG_LOSS_WEIGHT\n",
    "gamma = constants.TG_LOSS_WEIGHT\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=constants.REG_WEIGHT)\n",
    "pad_idx = tips_vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence shape:torch.Size([21, 2])\n",
      "init_hidden shape:torch.Size([1, 2, 400])\n",
      "No teacher forcing\n",
      "max_length:21\n",
      "decoder_var:tensor([[2, 2]])\n",
      "output_step: tensor([[[ -9.8530,  -9.9549,  -9.9495,  ...,  -9.9994,  -9.7837,  -9.8035],\n",
      "         [ -9.8580,  -9.9588,  -9.9538,  ..., -10.0080,  -9.8057,  -9.8045]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[1301, 1301]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-9.6105, -9.8587, -9.9511,  ..., -9.9865, -9.9172, -9.8148],\n",
      "         [-9.6135, -9.8633, -9.9563,  ..., -9.9924, -9.9279, -9.8150]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[7093, 7093]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.8132, -10.0887, -10.0526,  ..., -10.1143, -10.1154,  -9.7452],\n",
      "         [ -9.8143, -10.0920, -10.0561,  ..., -10.1177, -10.1202,  -9.7449]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[5974, 5974]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.6356,  -9.9666, -10.0502,  ...,  -9.9576,  -9.8693,  -9.6677],\n",
      "         [ -9.6356,  -9.9691, -10.0521,  ...,  -9.9595,  -9.8716,  -9.6676]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[11074, 11074]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.7860, -10.2117, -10.1604,  ...,  -9.8508,  -9.9555,  -9.9460],\n",
      "         [ -9.7863, -10.2131, -10.1618,  ...,  -9.8519,  -9.9564,  -9.9463]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[3273, 3273]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.8804,  -9.9055, -10.1111,  ..., -10.0679,  -9.9811,  -9.9641],\n",
      "         [ -9.8807,  -9.9065, -10.1121,  ..., -10.0687,  -9.9815,  -9.9644]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[12537, 12537]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.9495,  -9.9536, -10.2216,  ..., -10.0550, -10.0679,  -9.9192],\n",
      "         [ -9.9497,  -9.9541, -10.2222,  ..., -10.0554, -10.0682,  -9.9194]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[13256, 13256]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0127,  -9.8802,  -9.8699,  ...,  -9.9894, -10.0130, -10.0753],\n",
      "         [-10.0128,  -9.8804,  -9.8703,  ...,  -9.9896, -10.0131, -10.0754]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[4673, 4673]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.8776,  -9.9942,  -9.9597,  ..., -10.0363, -10.1570, -10.0240],\n",
      "         [ -9.8777,  -9.9944,  -9.9599,  ..., -10.0364, -10.1570, -10.0241]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[6902, 6902]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.9209, -10.0042,  -9.7890,  ...,  -9.9391,  -9.8610,  -9.9378],\n",
      "         [ -9.9209, -10.0043,  -9.7891,  ...,  -9.9392,  -9.8610,  -9.9378]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[10951, 10951]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0062,  -9.9143,  -9.8949,  ...,  -9.9391,  -9.8311, -10.0757],\n",
      "         [-10.0063,  -9.9143,  -9.8949,  ...,  -9.9391,  -9.8311, -10.0757]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[3981, 3981]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.1937,  -9.8334, -10.0075,  ...,  -9.7437,  -9.7881,  -9.9985],\n",
      "         [-10.1937,  -9.8334, -10.0075,  ...,  -9.7437,  -9.7880,  -9.9985]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[2002, 2002]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.9446,  -9.9810, -10.0120,  ...,  -9.6424,  -9.9139, -10.0542],\n",
      "         [ -9.9446,  -9.9810, -10.0120,  ...,  -9.6424,  -9.9139, -10.0542]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[3936, 3936]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0084,  -9.8797,  -9.8381,  ...,  -9.6528,  -9.8048,  -9.7516],\n",
      "         [-10.0084,  -9.8797,  -9.8381,  ...,  -9.6528,  -9.8048,  -9.7516]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[6023, 6023]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0846,  -9.8839,  -9.7629,  ...,  -9.5882,  -9.8532,  -9.8353],\n",
      "         [-10.0846,  -9.8839,  -9.7629,  ...,  -9.5882,  -9.8532,  -9.8353]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[13628, 13628]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0404,  -9.7729,  -9.9294,  ...,  -9.9050,  -9.6825, -10.0265],\n",
      "         [-10.0404,  -9.7729,  -9.9294,  ...,  -9.9050,  -9.6825, -10.0265]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[7511, 7511]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.9864, -10.0595, -10.0156,  ...,  -9.9509,  -9.9808,  -9.9704],\n",
      "         [ -9.9864, -10.0595, -10.0156,  ...,  -9.9509,  -9.9808,  -9.9704]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[9529, 9529]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[-10.0041,  -9.9950, -10.1853,  ...,  -9.9556,  -9.8440, -10.1281],\n",
      "         [-10.0041,  -9.9950, -10.1853,  ...,  -9.9556,  -9.8440, -10.1281]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[756, 756]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.6725, -10.0338,  -9.9009,  ...,  -9.8935, -10.0373, -10.1825],\n",
      "         [ -9.6725, -10.0338,  -9.9009,  ...,  -9.8935, -10.0373, -10.1825]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[6512, 6512]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.8063,  -9.9238,  -9.9566,  ...,  -9.8975,  -9.8793, -10.0793],\n",
      "         [ -9.8063,  -9.9238,  -9.9566,  ...,  -9.8975,  -9.8793, -10.0793]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[8548, 8548]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_step: tensor([[[ -9.8166,  -9.8796, -10.2826,  ...,  -9.7957,  -9.7644, -10.0354],\n",
      "         [ -9.8166,  -9.8796, -10.2826,  ...,  -9.7957,  -9.7644, -10.0354]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "output_step shape: torch.Size([1, 2, 19598])\n",
      "decoder_var:tensor([[3228, 3228]])\n",
      "decoder_var shape:torch.Size([1, 2])\n",
      "output_var: tensor([[[ -9.8530,  -9.9549,  -9.9495,  ...,  -9.9994,  -9.7837,  -9.8035],\n",
      "         [ -9.8580,  -9.9588,  -9.9538,  ..., -10.0080,  -9.8057,  -9.8045]],\n",
      "\n",
      "        [[ -9.6105,  -9.8587,  -9.9511,  ...,  -9.9865,  -9.9172,  -9.8148],\n",
      "         [ -9.6135,  -9.8633,  -9.9563,  ...,  -9.9924,  -9.9279,  -9.8150]],\n",
      "\n",
      "        [[ -9.8132, -10.0887, -10.0526,  ..., -10.1143, -10.1154,  -9.7452],\n",
      "         [ -9.8143, -10.0920, -10.0561,  ..., -10.1177, -10.1202,  -9.7449]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.6725, -10.0338,  -9.9009,  ...,  -9.8935, -10.0373, -10.1825],\n",
      "         [ -9.6725, -10.0338,  -9.9009,  ...,  -9.8935, -10.0373, -10.1825]],\n",
      "\n",
      "        [[ -9.8063,  -9.9238,  -9.9566,  ...,  -9.8975,  -9.8793, -10.0793],\n",
      "         [ -9.8063,  -9.9238,  -9.9566,  ...,  -9.8975,  -9.8793, -10.0793]],\n",
      "\n",
      "        [[ -9.8166,  -9.8796, -10.2826,  ...,  -9.7957,  -9.7644, -10.0354],\n",
      "         [ -9.8166,  -9.8796, -10.2826,  ...,  -9.7957,  -9.7644, -10.0354]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "output_var.shape: torch.Size([21, 2, 19598])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "idx = 0\n",
    "rmse_loss = 0.0\n",
    "num_ratings = 0\n",
    "for valid_batch in val_iter:\n",
    "    tips = valid_batch.tips\n",
    "    rate_output, tips_output, wd_output = model(valid_batch, tips[:-1], tf_rate=0)\n",
    "    # compute rmse\n",
    "#     rmse_loss += F.mse_loss(rate_output, valid_batch.rating, reduction='sum').item()\n",
    "#     num_ratings += valid_batch.rating.shape[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 2, 19598])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1301,  1301],\n",
      "        [ 7093,  7093],\n",
      "        [ 5974,  5974],\n",
      "        [11074, 11074],\n",
      "        [ 3273,  3273],\n",
      "        [12537, 12537],\n",
      "        [13256, 13256],\n",
      "        [ 4673,  4673],\n",
      "        [ 6902,  6902],\n",
      "        [10951, 10951],\n",
      "        [ 3981,  3981],\n",
      "        [ 2002,  2002],\n",
      "        [ 3936,  3936],\n",
      "        [ 6023,  6023],\n",
      "        [13628, 13628],\n",
      "        [ 7511,  7511],\n",
      "        [ 9529,  9529],\n",
      "        [  756,   756],\n",
      "        [ 6512,  6512],\n",
      "        [ 8548,  8548],\n",
      "        [ 3228,  3228]])\n"
     ]
    }
   ],
   "source": [
    "_, generate_idx = tips_output.max(2)\n",
    "print(generate_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  29,   35],\n",
      "        [  65,  633],\n",
      "        [  12, 1722],\n",
      "        [   5,  404],\n",
      "        [  64,   65],\n",
      "        [   3,    3],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1],\n",
      "        [   1,    1]])\n",
      "torch.Size([22, 2])\n"
     ]
    }
   ],
   "source": [
    "gts = None\n",
    "for valid_batch in val_iter:\n",
    "    tips = valid_batch.tips\n",
    "    gts = tips\n",
    "    print(tips[1:])\n",
    "    print(tips.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch first\n",
    "gts = torch.transpose(gts, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   29,   65,   12,    5,   64,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,   35,  633, 1722,  404,   65,    3,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "print(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_token = []\n",
    "for token_ids in gts:\n",
    "    current_sen = [tips_vocab.itos[id] for id in token_ids.detach().numpy()]\n",
    "    sentence_token.append(current_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_idx = torch.transpose(generate_idx, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1301,  7093,  5974, 11074,  3273, 12537, 13256,  4673,  6902, 10951,\n",
       "          3981,  2002,  3936,  6023, 13628,  7511,  9529,   756,  6512,  8548,\n",
       "          3228],\n",
       "        [ 1301,  7093,  5974, 11074,  3273, 12537, 13256,  4673,  6902, 10951,\n",
       "          3981,  2002,  3936,  6023, 13628,  7511,  9529,   756,  6512,  8548,\n",
       "          3228]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generate = []\n",
    "for token_ids in generate_idx:\n",
    "    current_sen = [tips_vocab.itos[id] for id in token_ids.detach().numpy()]\n",
    "    sentence_generate.append(current_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['service',\n",
       "  'shelling',\n",
       "  'sdhc',\n",
       "  'ampwas',\n",
       "  'ratings',\n",
       "  'dbm',\n",
       "  'es-57s',\n",
       "  'organ',\n",
       "  'outfit',\n",
       "  'agreat',\n",
       "  'playback',\n",
       "  'depends',\n",
       "  'k',\n",
       "  'stomping',\n",
       "  'fluctuations',\n",
       "  '9vdc',\n",
       "  'uh',\n",
       "  'quiet',\n",
       "  'drumming',\n",
       "  'klon',\n",
       "  'hammer'],\n",
       " ['service',\n",
       "  'shelling',\n",
       "  'sdhc',\n",
       "  'ampwas',\n",
       "  'ratings',\n",
       "  'dbm',\n",
       "  'es-57s',\n",
       "  'organ',\n",
       "  'outfit',\n",
       "  'agreat',\n",
       "  'playback',\n",
       "  'depends',\n",
       "  'k',\n",
       "  'stomping',\n",
       "  'fluctuations',\n",
       "  '9vdc',\n",
       "  'uh',\n",
       "  'quiet',\n",
       "  'drumming',\n",
       "  'klon',\n",
       "  'hammer']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score.sentence_bleu(sentence_token[1], sentence_generate[1], weights=[1.0,0.0,0.0,0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
